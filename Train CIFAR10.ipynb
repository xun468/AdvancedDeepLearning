{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from art.attacks import FastGradientMethod, ProjectedGradientDescent\n",
    "from art.classifiers import KerasClassifier\n",
    "from art.utils import load_dataset\n",
    "from art.attacks import BasicIterativeMethod\n",
    "from art.defences import AdversarialTrainer\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import adam\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras import applications\n",
    "from keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str('cifar10'))\n",
    "# (x_train1, y_train1), (x_test1, y_test1) = cifar10.load_data() # difference is only one hot y vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PARTIAL_DATA = True   # how much of data we use for training\n",
    "PARTIAL_SIZE = 256*4\n",
    "\n",
    "USE_WEIGHT_DECAY = False\n",
    "USE_DATA_AUGMENTATION = False\n",
    "\n",
    "USE_RETRAINING = True   # Either use retrain or train directly using PGD\n",
    "\n",
    "VERBOSITY = 1  # Keras fit verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\lgran\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "batch_size = 256\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "\n",
    "retraining_rounds = 2\n",
    "epochs_per_round = 2\n",
    "\n",
    "lr = 0.0001 # lr = 0.01\n",
    "optimizer = Adam(lr=lr) # keras.optimizers.SGD(lr=lr, momentum=momentum) # Adam(lr=lr)\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "#Adv training\n",
    "norm = 2\n",
    "eps = 0.5\n",
    "steps = 7\n",
    "step_size = 0.1\n",
    "adv_ratio = 1.0\n",
    "targeted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "no_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.resnet50.ResNet50(weights=None, include_top=True, input_shape=input_shape, classes=no_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WEIGHT_DECAY:   # https://jricheimer.github.io/keras/2019/02/06/keras-hack-1/\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
    "            layer.add_loss(keras.regularizers.l2(weight_decay)(layer.kernel))\n",
    "        if hasattr(layer, 'bias_regularizer') and layer.use_bias:\n",
    "            layer.add_loss(keras.regularizers.l2(weight_decay)(layer.bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_PARTIAL_DATA:\n",
    "    x_train, y_train = x_train[:PARTIAL_SIZE], y_train[:PARTIAL_SIZE]\n",
    "    x_test, y_test = x_test[:PARTIAL_SIZE], y_test[:PARTIAL_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\lgran\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3298: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\lgran\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "classifier = KerasClassifier(model=model, clip_values=(min_, max_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = ProjectedGradientDescent(classifier=classifier, norm=norm, eps=eps, eps_step=step_size, max_iter=steps, targeted=targeted, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE TRAINING:\n",
      "Accuracy on benign test examples: 12.0%\n",
      "Accuracy on adversarial test examples: 10.0%\n"
     ]
    }
   ],
   "source": [
    "test_size = 100\n",
    "print(\"BEFORE TRAINING:\")\n",
    "predictions = classifier.predict(x_test[:test_size])\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:test_size], axis=1)) / len(y_test[:test_size])\n",
    "print('Accuracy on benign test examples: {}%'.format(accuracy * 100))\n",
    "\n",
    "x_test_adv = attack.generate(x=x_test[:test_size])\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:test_size], axis=1)) / len(y_test[:test_size])\n",
    "print('Accuracy on adversarial test examples: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4/4 [==============================] - ETA: 1:34 - loss: 4.3182 - acc: 0.097 - ETA: 49s - loss: 4.0121 - acc: 0.103 - ETA: 22s - loss: 3.8129 - acc: 0.11 - 87s 22s/step - loss: 3.6492 - acc: 0.1250\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - ETA: 55s - loss: 2.8626 - acc: 0.17 - ETA: 36s - loss: 2.7092 - acc: 0.20 - ETA: 18s - loss: 2.6393 - acc: 0.20 - 74s 18s/step - loss: 2.6811 - acc: 0.1982\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - ETA: 49s - loss: 3.7577 - acc: 0.10 - ETA: 33s - loss: 3.6813 - acc: 0.08 - ETA: 16s - loss: 3.7408 - acc: 0.07 - 67s 17s/step - loss: 3.7406 - acc: 0.0703\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - ETA: 49s - loss: 3.6734 - acc: 0.08 - ETA: 32s - loss: 3.3959 - acc: 0.08 - ETA: 16s - loss: 3.3061 - acc: 0.09 - 66s 17s/step - loss: 3.2289 - acc: 0.0996\n",
      "Epoch 1/2\n",
      "4/4 [==============================] - ETA: 47s - loss: 3.8583 - acc: 0.05 - ETA: 31s - loss: 3.7596 - acc: 0.07 - ETA: 15s - loss: 3.6864 - acc: 0.06 - 64s 16s/step - loss: 3.4825 - acc: 0.0781\n",
      "Epoch 2/2\n",
      "4/4 [==============================] - ETA: 50s - loss: 3.1660 - acc: 0.09 - ETA: 33s - loss: 3.0665 - acc: 0.11 - ETA: 16s - loss: 3.0356 - acc: 0.12 - 67s 17s/step - loss: 3.0175 - acc: 0.1260\n"
     ]
    }
   ],
   "source": [
    "if USE_RETRAINING:\n",
    "    # Initial training\n",
    "    classifier.fit(x_train, y_train, nb_epochs=epochs, batch_size=batch_size, verbose=VERBOSITY)\n",
    "    \n",
    "    # Retraining for adversarial examples\n",
    "    for i in range(retraining_rounds):\n",
    "        print(\"Retraining round {}/{}\".format(i+1, retraining_rounds))\n",
    "        # Generating adv examples\n",
    "        attack = ProjectedGradientDescent(classifier=classifier, norm=norm, eps=eps, eps_step=step_size, max_iter=steps, targeted=targeted, batch_size=batch_size)\n",
    "        adv_x_train = attack.generate(x=x_train, y=y_train)\n",
    "        \n",
    "        # Retraining, a few fewer epochs I guess?\n",
    "        classifier.fit(adv_x_train, y_train, nb_epochs=epochs_per_round, batch_size=batch_size, verbose=VERBOSITY)\n",
    "\n",
    "else:\n",
    "    trainer = AdversarialTrainer(classifier, attack, ratio=adv_ratio)\n",
    "    trainer.fit(x_train, y=y_train, nb_epochs=epochs, batch_size=batch_size, verbose=VERBOSITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER TRAINING:\n",
      "Accuracy on benign test examples: 19.0%\n",
      "Accuracy on adversarial test examples: 12.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"AFTER TRAINING:\")\n",
    "predictions = classifier.predict(x_test[:test_size])\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:test_size], axis=1)) / len(y_test[:test_size])\n",
    "print('Accuracy on benign test examples: {}%'.format(accuracy * 100))\n",
    "\n",
    "attack = ProjectedGradientDescent(classifier=classifier, norm=norm, eps=eps, eps_step=step_size, max_iter=steps, targeted=targeted, batch_size=batch_size)\n",
    "x_test_adv = attack.generate(x=x_test[:test_size])\n",
    "predictions = classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test[:test_size], axis=1)) / len(y_test[:test_size])\n",
    "print('Accuracy on adversarial test examples: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lgran\\Documents\\GitHub\\AdvancedDeepLearning\n"
     ]
    }
   ],
   "source": [
    "# Saving trained model\n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "classifier.save(filename=\"robust_test.h5\", path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classifier.fit(x_train, y_train, nb_epochs=25, batch_size=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = np.argmax(classifier.predict(x_train), axis=1)\n",
    "# print(preds[0])\n",
    "# acc = np.sum(preds == np.argmax(y_train)) / y_train.shape[0]\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = classifier.predict(x_test)\n",
    "# accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "# print('Accuracy on benign test examples: {}%'.format(accuracy * 100))\n",
    "# \n",
    "# # Step 6: Generate adversarial test examples\n",
    "# attack = FastGradientMethod(classifier=classifier, eps=0.2)\n",
    "# x_test_adv = attack.generate(x=x_test)\n",
    "# \n",
    "# # Step 7: Evaluate the ART classifier on adversarial test examples\n",
    "# \n",
    "# predictions = classifier.predict(x_test_adv)\n",
    "# accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "# print('Accuracy on adversarial test examples: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_adv = attack.generate(x=x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classifier.fit(x_train_adv, y_train, nb_epochs=10, batch_size=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 7: Evaluate the ART classifier on adversarial test examples\n",
    "# predictions = classifier.predict(x_test)\n",
    "# accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "# print('Accuracy on benign test examples: {}%'.format(accuracy * 100))\n",
    "# \n",
    "# predictions = classifier.predict(x_test_adv)\n",
    "# accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "# print('Accuracy on adversarial test examples: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following this tutorial https://github.com/IBM/adversarial-robustness-toolbox/blob/master/examples/adversarial_training_cifar10.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# path = os.getcwd()\n",
    "# print(path)\n",
    "# classifier.save(filename=\"testing\", path=path)\n",
    "# \n",
    "# from keras.models import load_model\n",
    "# model2 = load_model(path+\"/testing\")\n",
    "# classifier2 = KerasClassifier(model=model2, clip_values=(min_, max_))\n",
    "# \n",
    "# preds = np.argmax(classifier2.predict(x_train), axis=1)\n",
    "# print(preds[0])\n",
    "# acc = np.sum(preds == np.argmax(y_train)) / y_train.shape[0]\n",
    "# print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_generator(generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
    "# \n",
    "# fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
